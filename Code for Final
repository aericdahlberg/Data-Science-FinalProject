import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
import matplotlib.pyplot as plt


df = pd.read_csv("winequality-red.csv")
print(df.head()) #show first few rows

sns.barplot(x ="quality", y ="sulphates", capsize=.1, data = df)
plt.show()
sns.barplot(x ="quality", y ="citric acid", capsize=.1, data = df)
plt.show()
sns.barplot(x ="quality", y ="volatile acidity", capsize=.1, data = df)
plt.show()
sns.barplot(x ="quality", y ="alcohol", capsize=.1, data = df)
plt.show()


plt.subplots(figsize = (20,17))

plt.subplots(figsize = (15, 7))
sns.set(font_scale = 0.7)
plt.title("Red Wine Data Heatmap", fontsize= 35, fontweight= "bold")
heatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')
plt.savefig("heatmap.svg")


######Deep learning#####


model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['accuracy'])
# Fit the model
history = model.fit(X, Y, validation_split=0.33, epochs=5, batch_size=3, verbose=0)
# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
model.add(Dense(12, input_dim=8, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='categorical_crossentropy', optimizer='adam')

# train the model for 10 epochs
history = model.fit(X_train, y_train, epochs=10)

# plot the loss values for each epoch
plt.plot(history.history['loss'])
plt.show()
